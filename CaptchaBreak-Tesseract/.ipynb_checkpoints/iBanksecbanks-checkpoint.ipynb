{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from time import sleep, time\n",
    "from random import randint\n",
    "import re\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "from selenium import webdriver \n",
    "import cv2 \n",
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_captcha_page(soup):\n",
    "    captcha_text=\"Please verify you are human by typing the text below and clicking submit.\"\n",
    "    page_info=soup.find('font',attrs={'class':\"pagebodybold\"})\n",
    "    if page_info!=None and captcha_text in page_info.text:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_captcha(company_link):\n",
    "    driver = webdriver.Firefox('/home/udit/projects/chromiumm')\n",
    "    driver.get(company_link)\n",
    "    element = driver.find_element_by_id(\"imgCaptcha\")\n",
    "    element.screenshot('final.png')\n",
    "    img = cv2.imread('final.png')\n",
    "    captcha=pytesseract.image_to_string(img)\n",
    "    \n",
    "    captcha=re.sub(r'\\W+', '', captcha)\n",
    "    captcha_input = driver.find_element_by_xpath(\"//input[@id ='txtCaptcha']\") \n",
    "    captcha_input.send_keys(captcha) \n",
    "\n",
    "    # submit button clicked\n",
    "    driver.find_element_by_xpath(\"//input[@id ='btnRegiser']\").click()\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    driver.close()\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_filling(strr,company_info):\n",
    "    try:\n",
    "        global x\n",
    "        eqn= \"{0} = {1}\".format(\"x\",strr)\n",
    "        x = np.nan\n",
    "        exec(eqn,globals())\n",
    "        return x\n",
    "    except IndexError:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://ibanknet.com/scripts/callreports/fiList.aspx?type=secbanks\"\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies=soup.find_all('a', attrs = {'class':'pagebody'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_companies=[]\n",
    "\n",
    "for company in companies:\n",
    "    company_link=\"https://ibanknet.com/\"+company.get('href')\n",
    "    error_links=[]\n",
    "    try:\n",
    "        c = requests.get(company_link)\n",
    "        soup = BeautifulSoup(c.content, 'html5lib')\n",
    "\n",
    "        while(is_captcha_page(soup)):\n",
    "            soup=solve_captcha(company_link)\n",
    "\n",
    "        company_info=[]\n",
    "\n",
    "        for info in soup.find_all('td', attrs = {'class':'instinfo'}):\n",
    "            company_info.append(info.text)\n",
    "\n",
    "\n",
    "        company_inf={}\n",
    "        company_inf[\"company_name\"]=soup.find('font',attrs={'class':\"blockuhilite\"}).text.strip()\n",
    "        company_inf[\"RSSD_ID\"]=company_info[0].split()[company_info[0].split().index(\"RSSD\")+2]\n",
    "        company_inf['RefinedAddress']=company_info[1]\n",
    "        company_inf['City']=company_info[4].split(\",\")[0].strip()\n",
    "        company_inf['State']=company_info[4].split(\",\")[1].strip()\n",
    "        company_inf['Pin']=try_filling(company_info[4].split(\",\")[2].strip(),company_info)\n",
    "        company_inf['webAddress']=company_info[7].strip() if ('.com' in company_info[7].strip()) else np.nan\n",
    "        company_inf['EntityType']=company_info[company_info.index('Entity Type : ')+1]\n",
    "        company_inf['Incorporated']=company_info[company_info.index('Incorporated : ')+1]\n",
    "        company_inf['SIC_Code']=company_info[company_info.index('SIC Code : ')+1]\n",
    "        #company_inf['FederalRegulator']=company_info[company_info.index('Federal Regulator :')+1]\n",
    "        company_inf['FiscalYearEnd']=company_info[company_info.index('Fiscal Year End : ')+1]\n",
    "        company_inf['Regulator']=company_info[company_info.index('Regulator : ')+1]\n",
    "        company_inf['FilerStatus']=company_info[company_info.index('Filer Status : ')+1]\n",
    "\n",
    "        all_companies.append(company_inf)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_links.append([company_link,str(e)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_compaies=pd.DataFrame(all_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_compaies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_links=[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
